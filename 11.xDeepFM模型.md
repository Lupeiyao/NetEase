xDeepFM是中科大、北大、微软在2018联合发表的DNN CTR模型。

#### 背景

FNN，DCN和Wide&Deep的Deep部分都是基于Embedding+DNN做的隐式特征交叉，即（类别维度）的特征交叉。

PNN和DeepFM通过修改直接从Embedding到DNN的过程增加了显示的特征交叉（特征维度）的交叉。

DCN则是通过残差网络进行了显示的特征维度的交叉。问题有二：

- DCN网络的结构被限制了，每层神经元个数必须和Embedding的维度一样。
- 通过公式可以发现，DCN的交叉是在特征维度的。

文章提出一种CIN模型，解决三个问题：

- 在类别维度进行特征交叉
- 显式的高阶特征交叉
- 复杂度不随着网络层数的增加指数级上升

#### xDeepFM解决方案

![](C:\Users\Lunus\Desktop\推荐系统\图\xDeepFM架构图 .jpg)

- CIN的输入$x^0 \in R^{m*D}，x_{i,*}^0=embed_i$，可以看做一个矩阵，每层输出都是一个矩阵。其中m是域的数量，D是Embedding的维度。k层网络的输出，其中H表示输出的向量个数，W是参数
  $$
  x_{h,*}^k=\sum_{i=1}^{H_{k-1}}\sum_{j=1}^mW_{ij}^{k,h}(X_{i,*}^{k-1} \circ x_{j,*}^0)\\
  <a,b,c> \circ <d,e,f> = <ad,be,cf>
  $$

  - 计算公式其实很简单，两层for循环遍历x^k -1和 x^0 的每一行，做乘法，然后利用一个矩阵加权求和得到一个向量。H^K个矩阵就得到H^k个向量。
  - 其中第k层的输出是由k-1层的输入和x_0计算得到的，是显式的类别级的特征交叉。
  - 同时第k层的输出只包含k+1阶的交叉，而DCN包含所有从1-k+1的交叉。所以最后出去的连接DCN只要最后一层，而CIN每层都要。

- 如图c，将每个矩阵按照行求和得到一个向量，将每层的向量拼接得到一个最终输出P^+，CIN共T层。
  $$
  \begin{align}
  \hat{y}&=\sigma(p^+w^0)\\
  p+ &= [p^1,p^2,...,p^T]\\
  p^k&=[p_1^k,p_2^k,...,p_{H_k}^k]\\
  p_i^k&=\sum_{j=1}^DX_{i,j}^k
  \end{align}
  $$

- 输出

$$
\hat{y}=\sigma(w_{linear}^Ta+w_{dnn}^Tx_{dnn}^k+w_{cin}^Tp^++b)
$$

​	

#### 实验

- 超参数用验证集得到
- 使用Adam最优化，ReLU，学习率0.001
- batch-size=4096
- CIN=200，DNN=400
- Embedding= 10