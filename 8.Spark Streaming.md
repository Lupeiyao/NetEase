- Streaming Demo

Spark会把流数据按照时间间隔分成多个RDD，流处理实际上是对各个RDD的处理，注意cores(线程数)需要多于receiver的数量，每个receiver会占用一个线程，其他线程用来处理输入，一次只能启动一个StreamingContext。
```
val conf = new SparkConf().setMater("local").setAppName("app_name")

val ssc = new StreamingContext([conf | sc], Seconds(1))

val lines = ssc.socketTextStream("ip",port)
val words = lines.flatMap(line => line.split(" "))

import org.apache.spark.streamint.StreamingContext._

val wordCounts = words.map(word=>(word,1))
                    .reduceByKey(_ + _)
wordCounts.print()
//显示的调度才会开始计算，在另一个线程
ssc.start()
//主线程等待，不然程序就退出了
ssc.awaitTermination()

```

- 输入输出

输入支持FileStreams,RDD队列，Custom Receivers,Kafka,Flume

输出支持print,textFile,ObjectFile,HadoopFile,foreachRDD

具体参见官方文档


- 无状态操作

各时间段（批次）的RDD之间没有关系，比如对实时的每个样本进行异常检测，批次与批次之间无关，函数只针对每个批次的RDD进行处理
```
val srdd = ssc.xxxx
val abnormals = srdd.map(model.predict(_))
abnormals.print()

srdd.[map | flatMap | filter | repartation | reduceByKey groupByKey]

srdd.[join | cogroup | leftOuterJoin....]

val ipAndContent = logs.map(log=>(log.ip,log.content.size))

//处理每个批次的rdd
srdd.transform(rdd=>rdd)

```

- 有状态操作
```
//利用划窗计算多个批次的数据，例：求和
val windowSRdd = srdd.window(window_size,slide_size)
windosSRdd.reduce(_ + _)

srdd.reduceByWindow(_ + _,window_size,slide_size)
//简化操作，新增批次增加，丢失的批次减少，未变的划窗不变
srdd.reduceByWindow((x,y)=>x+y,(x,y)=>x-y,win_size,slide_size)

//利用状态值在多个批次之间传递,例：求当前所有数的和
def fun(values : Seq[Type], state : Option[Any]) = {
    val value = state.getOrElse(value : Any)
    some(values,state) -> new_state : Option
}
srdd.updateStateByKey(fun _)
```

- 容错
```
ssc.checkpoint("hdfs://...")
```
