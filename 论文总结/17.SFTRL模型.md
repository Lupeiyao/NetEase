####Sketched Follow-The-Regularized-Leader for Online Factorization Machine

本文由上海交通大学、清华大学、北京大学、腾讯AI Lab联合发表于KDD 2018。针对FM算法如何在线学习，提出了Sketched Follow-The-Regularizer-Leader的优化算法，并和OGD、OCG和FTRL算法进行了对比。 

#### 背景

现有的在线的FM算法当数据维度非常高时，计算成本太高。

#### 解决方案

在线凸优化结合FM算法的瓶颈是历史梯度和的更新和存储，为此引入sketching，可以将大型矩阵转化为小很多的矩阵以避免超大的运算量，FD算法是一个确定性的sketching，即使sketch size很小也是数值稳定的，但是原始的FD要求矩阵半正定，然而在FM当中不能保证，有可能存在负定的情况，因此提出了FD的改进算法GFD：

图1

![1553245506654](C:\Users\ADMINI~1\AppData\Local\Temp\1553245506654.png)

然后为了避免其中的复杂运算，又提出了GFD with Doubling Space ，且保证了时间复杂度和GFD一样：

图2

![1553245751668](C:\Users\ADMINI~1\AppData\Local\Temp\1553245751668.png)

然后引入GFD来估算FTRL（Follow-The-Regularized-Leader）历史梯度的和，然后推导出用于FM的SFTRL（sketched Follow-The-Regularized-Leader）：

图3

![1553247372599](C:\Users\ADMINI~1\AppData\Local\Temp\1553247372599.png)

文章第四部分对SFTRL进行了理论分析，证明了SFTRL的regret bound非常接近标准的FTRL。

#### 实验结果

分别完成两个任务：在线评级预测推荐和在线二分类，实验表明在三个不同的数据集上，RMSE（root mean square error）均优于其他在线模型，且耗时至少缩小了两个量级；在线分类任务中，AUC（Area Under Curve）均优于其他模型，耗时至少缩小了一半。

