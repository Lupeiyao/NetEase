#### Ranking FM

本文是北京大学发表于 CIKM 2013上的基于FM改进的Ranking FM，用于微博检索的模型

#### 背景

以往的排序算法用于信息检索领域中，很少考虑各种相关特征之间的相互作用。本文将学习的一般性和排序框架与分解模型的优势结合，估计特征之间的相互作用，从而获得更好的检索性能。

#### 解决方案

采用FM作为排序函数来模拟特征之间的相互作用

假设$f_{\Theta}(x)$代表$d=2$时的FM函数：

$f_{\Theta}(x) = w_0 + \sum_{i=1}^{n}w_ix_i + \sum_{i=1}^{n}\sum_{j=i+1}^{n}x_ix_j\sum_{f=1}^{k}v_{i,f},v_{j,f}$

然后，我们将任意样本对和他们之间的关系组成一个带有新标签的新样本集，令$p$和$q$表示样本对中的第一个和第二个样本，$y_p$和$y_q$表示他们的排序

$\left((p,q),z=\begin{cases}+1,y_p>y_q\\-1,y_q>y_p\end{cases}\right)$

这样，我们从已给的训练数据集$S$中得到了一个新的训练数据集$S'=\{(p^{(t)},q^{(t)}),z^{(t)}\}_{i=1}$	，然后计算$S'$中的第$t$个样本对的经验损失，“+”代表正的部分：

$l_i(f;p^{(t)},q^{(t)},z)=[1-z\times(f_{\Theta}(p^{(t)})-f_{\Theta}(q^{(t)}))]_+$

其中$f_{\Theta}(p^{(t)})$和$f_{\Theta}(q^{(t)})$可以根据FM中的公式计算出来，且复杂度为$O(kn)$

我们可以根据上式给出总的损失函数(加了$L_2$正则项）：

$min_{\Theta}L(\Theta)=\sum_{t=1}^ll_t(f;p^{(t)},q^{(t)},z^{(t)})+\sum_{\theta\in\Theta}\lambda_{\theta}\theta^2$

另外本文中，用SGD和自适应的正则项对上述损失函数进行优化：

利用SGD进行参数更新：$\theta=\theta-\eta(\frac{\partial l_t}{\partial \theta}+2\lambda_\theta \theta)$

自适应正则化（Adaptive Regularization）：

​	1.在训练集$S_T$中，对具有当前正则项常数$\lambda^{(t)}$的正则化损失目标，优化未来模型参数$\Theta^{(t+1)}$；

​	2.在验证集$S_V$中， 目标是使用使得loss最小的已更新的模型参数$\Theta^{(t+1)}$来确定最好的未来正则项参数$\lambda^{(t+1)}$

#### 创新点：

1.将FM模型改进为Ranking FM用于检索排序；

2.使用了SGD和自适应正则项







