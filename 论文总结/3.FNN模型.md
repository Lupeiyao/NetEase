FNN（Factorisation Machine supported Neural Network）是2016年提出来的基于FM的DNN CTR模型。

#### 背景

FM可以解决稀疏问题，但只能表达二阶特征组合，无法表达高阶特征组合，表达能力有限。DNN表达能力强，可以学习高阶特征组合

而且扩展性强，对于图片，文字类特征容易扩展。文章提出一种基于FM的DNN模型（FNN）。

#### FNN解决方案

![](C:\Users\Lunus\Desktop\推荐系统\图\FNN架构图.jpg)

- 首先训练一个FM模型得到$w_0，w_i，v_i​$
- 接着构造一个三层全连接的DNN网络，第三层是输出层，激活函数是sigmod，第二层有L个神经元，激活函数是tanh，第一层有M个神经元，激活函数也是tanh

$$
\begin{align}
\hat{y}&=\sigma(W_3l_2+b_3)\\
l_2&=tanh(W_2l_1+b_2)\\
l_1&=tanh(W_1z+b_1)\\
z&=(w_0,z_1,...,z_i,...,z_n)\\
\end{align}
$$

- 其中每个域产生一个$z_i$，计算公式如下，权重由FM初始化
  $$
  z_i=W_0^i \cdot x[start_i:end_i]=(w_i,v_i^1,v_i^2,...,v_i^K)
  $$
  

#### 正则化

- L2
- Dropout
- early stopping

#### 实验

- 使用SGD训练
- 使用了三个隐藏层。
- 增每层选取（200,300,100）神经元