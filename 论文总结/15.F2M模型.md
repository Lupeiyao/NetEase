### F2M：Scalable Field-Aware Factorization Machines

文章是北京大学发表于NIPS 2016，基于FFM提出了可扩展的FFM的分布式系统

#### 背景

FFM在高维稀疏数据上有较好的性能，但是目前的FM系统均是在一台机器上运行，计算能力和存储都可能达到上限，因此提出了FFM的分布式实现。

#### 解决方案

文章分析了AllReduce、MapReduce-like、ParameterServer三种架构方式的利弊，最终

选择了参数服务器（parameter server）作为底层计算引擎（原因：由于FFM的模型参数通常来说比较多，AllReduce和MapReduce可能会面对非常大的网络和同步开销，且在PS上单机版的FFM模型移植较为简单）

图1

![1553258890692](C:\Users\ADMINI~1\AppData\Local\Temp\1553258890692.png)

F2M的设计：

图2

![1553259511784](C:\Users\ADMINI~1\AppData\Local\Temp\1553259511784.png)

F2M划分为三个部分，master节点运行控制逻辑（维护每个worker和server进程）；server节点更新模型（存储参数，处理聚合，更新操作）；worker节点计算梯度（存储一部分训练数据以计算梯度）。worker节点只允许和server节点、master节点通信，他们之间不运行通信。

另外，F2M支持异步计算。

#### 系统优化

1.信息压缩：（1）避免发送单个item，将item打包成batch block进行迭代以减少每条信息的大小；（2）许多ML问题在不同迭代中使用相同的训练数据，因此将密钥列表缓存在接收节点中，发件人智能发送此列表的哈希值，而不是列表；（3）使用Protobuf序列化信息，并进一步使用Snappy压缩库来压缩序列化信息；（4）使用有损定点压缩进行数据通信，默认情况下，模型参数和梯度等都表示为32位浮点数，在F2M中，我们将这些值压缩为较低精度的整数

2.信息传输：为了最大化CPU利用率并减少延迟，F2M实现了两个信号队列作为内存缓冲区；将计算和网络放在两个线程中，网络不会阻塞计算；使用了零复制技术，传递指针而不是数据。

#### 实验

使用了L1正则项（不仅是作为惩罚项，而且L1正则项更容易导致稀疏，降低了梯度计算开销）

实验结果表明：使用了32台机器，F2M实现了18.5倍的加速，在单台机器上同样有很好的性能