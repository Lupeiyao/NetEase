DeepFM是华为在2017年提出的基于FM与DNN的CTR模型，论文中效果优于FM，FFM，FNN，PNN，Wide&Deep模型。

#### 背景

CTR问题中的稀疏问题由FM很好的进行了解决，但FM只能解决二阶特征组合，为了提高模型对高阶特征组合的能力，使用了DNN来捕捉高阶特征。

但DNN对于稀疏数据很难处理，所以提出了FM+DNN的模型即DeepFM，而且不需要提前对FM预训练（不同于Wide&Deep）。

#### DeepFM解决方案

![](C:\Users\Lunus\Desktop\推荐系统\图\DeepFM结构图.jpg)

看着复杂，其实就是FM+DNN。。。。

- 首先，输入$x$通过FM层得到了Embedding向量，其中$e_i$是域$i$的非零特征得到的Embedding向量（FM中的$v_j(x_j \in field_i ,x_j\not=0)​$）
  $$
  a^{(0)}=[e_1,e_2,...,e_m]
  $$

- 接着将FM的Embedding向量输入全连接的DNN（Hidden Layer），同时计算原始FM（FM Layer）的输出。
  $$
  \begin{align}
  \hat{y}&=\sigma(y_{FM}+y_{DNN})\\
  y_{FM}&=w_0+\sum_{i=1}^nw_ix_i+\sum_{i=1}^n\sum_{j=i+1}^n<v_i,v_j>x_ix_j\\
  y_{DNN}&=\sigma(W^{H+1} \cdot a^H + b^{H+1})
  \end{align}
  $$

- 完了。。。。。。

#### 实验

测试了ReLU和tanh两个激活函数，RELU比较好。

在Criteo数据集和某公司数据集上表现（AUC和LogLoss）都优于其他模型。

增加了Dropout，发现还可以。

模型对于每层神经元个数和隐层个数的改变是稳定的。每层200-400的神经元比较好。