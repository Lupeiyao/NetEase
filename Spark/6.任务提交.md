# 提交脚本
可以使用任何拥有Spark软件的节点提交spark任务到集群。
使用spark/bin/spark-submit 提交任务
- 说明
```
spark-submit [spark参数] [app] [app参数]
//spark参数
--master [spark://hostname:port | yarn | ....]
--queue [queName] //yarn参数
--deploy-mode [client | cluster]
//yarn参数，每个executors的线程数
--executors-cores [num]
//StandAlone、Mesoso参数，总核心数
--total-executor-cores [num]
--executors-memory [10g]
--executors-cores [num] 
--driver-memory [10g]
--jars [依赖jar包]
--class [运行main的入口类]
--name [spark app name]
```
- shell脚本
```
./bin/spark-submit \
--master spark://Lunus-Master:7077  \
--queue abcqueue[yarn]              \
--deploy-mode client                \
#Yarn参数，每个executor核心数
--executors-cores 2                 \
#StandAlone，Mesos参数，总核心数
--total-executor-cores 100          \
--num-executors 50                  \
--executros-memory 10g              \
--driver-memory 20g                 \
--jars xxx.jar xxx.jar xxx.jar      \
--class lab.sse.logAnalysis.GMM     \
--name logAnalysisApp               \
log.jar "static" "100" "20"         \
```

- 也可以通过配置文件 spark/conf/spark-defaults.conf
```
spark.master                    spark://Lunus-Master:7077
spark.submit.deployMode         client
#yarn参数，每个executor核心数
spark.executor.cores            2
#StandAlone，Mesos参数，总最大核心数
spark.cores.max                 8
spark.executor.memory           1G
spark.dirver.memory             2G
spark.app.name		        	    test
```
