# 提交脚本
可以使用任何拥有Spark软件的节点提交spark任务到集群。
使用spark/bin/spark-submit 提交任务
- 说明
```
spark-submit [spark参数] [app] [app参数]
//spark参数
--master [spark://hostname:port | yarn | ....]
--deploy-mode [client | cluster]
--executors-cores [num] //每个executors的线程数
--num-executors [num]
--executors-memory [10g]
--driver-memory [10g]
--jars [依赖jar包]
--class [运行main的入口类]
--name [spark app name]
--queue [queName] //yarn参数
```
- shell脚本
```
./bin/spark-submit \
--master spark://Lunus-Master:7077  \
--queue abcqueue[yarn]              \
--deploy-mode client                \
--executors-cores 2                 \
--num-executors 50                  \
--executros-memory 10g              \
--driver-memory 20g                 \
--jars xxx.jar xxx.jar xxx.jar      \
--class lab.sse.logAnalysis.GMM     \
--name logAnalysisApp               \
log.jar "static" "100" "20"         \
```

- 也可以通过配置文件 spark/conf/spark-defaults.conf
```
spark.master                    spark://Lunus-Master:7077
spark.submit.deployMode         client
spark.executor.cores            2
spark.cores.max                 8
spark.executor.memory           1G
spark.dirver.memory             2G
spark.app.name		        	test
```
